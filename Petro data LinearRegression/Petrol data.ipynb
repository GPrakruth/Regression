{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# External Lab \n",
    "\n",
    "Here each question is of 1 mark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Use Multiple Linear Regression to **predict the consumption of petrol** given relevant variables are the petrol tax, the per capita, income, the number of miles of paved highway, and the proportion of the population with driver's licenses.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "There are 48 rows of data.  The data include:\n",
    "\n",
    "      I,  the index;\n",
    "      A1, the petrol tax;\n",
    "      A2, the per capita income;\n",
    "      A3, the number of miles of paved highway;\n",
    "      A4, the proportion of drivers;\n",
    "      B,  the consumption of petrol.\n",
    "\n",
    "### Reference \n",
    "\n",
    "    Helmut Spaeth,\n",
    "    Mathematical Algorithms for Linear Regression,\n",
    "    Academic Press, 1991,\n",
    "    ISBN 0-12-656460-4.\n",
    "\n",
    "    S Weisberg,\n",
    "    Applied Linear Regression,\n",
    "    New York, 1980, pages 32-33.\n",
    "\n",
    "## Question 1 - Exploratory Data Analysis\n",
    "\n",
    "*Read the dataset given in file named **'petrol.csv'**. Check the statistical details of the dataset.*\n",
    "\n",
    "**Hint:** You can use **df.describe()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from scipy.stats import ttest_ind, ttest_1samp, levene, shapiro, f_oneway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tax   income   highway     dl   consumption\n",
      "0  9.0     3571      1976  0.525           541\n",
      "1  9.0     4092      1250  0.572           524\n",
      "2  9.0     3865      1586  0.580           561\n",
      "3  7.5     4870      2351  0.529           414\n",
      "4  8.0     4399       431  0.544           410\n",
      "    tax   income   highway     dl   consumption\n",
      "43  7.0     3745      2611  0.508           591\n",
      "44  6.0     5215      2302  0.672           782\n",
      "45  9.0     4476      3942  0.571           510\n",
      "46  7.0     4296      4083  0.623           610\n",
      "47  7.0     5002      9794  0.593           524\n",
      "(48, 5)\n",
      "      tax   income   highway     dl   consumption\n",
      "0    9.00     3571      1976  0.525           541\n",
      "1    9.00     4092      1250  0.572           524\n",
      "2    9.00     3865      1586  0.580           561\n",
      "3    7.50     4870      2351  0.529           414\n",
      "4    8.00     4399       431  0.544           410\n",
      "5   10.00     5342      1333  0.571           457\n",
      "6    8.00     5319     11868  0.451           344\n",
      "7    8.00     5126      2138  0.553           467\n",
      "8    8.00     4447      8577  0.529           464\n",
      "9    7.00     4512      8507  0.552           498\n",
      "10   8.00     4391      5939  0.530           580\n",
      "11   7.50     5126     14186  0.525           471\n",
      "12   7.00     4817      6930  0.574           525\n",
      "13   7.00     4207      6580  0.545           508\n",
      "14   7.00     4332      8159  0.608           566\n",
      "15   7.00     4318     10340  0.586           635\n",
      "16   7.00     4206      8508  0.572           603\n",
      "17   7.00     3718      4725  0.540           714\n",
      "18   7.00     4716      5915  0.724           865\n",
      "19   8.50     4341      6010  0.677           640\n",
      "20   7.00     4593      7834  0.663           649\n",
      "21   8.00     4983       602  0.602           540\n",
      "22   9.00     4897      2449  0.511           464\n",
      "23   9.00     4258      4686  0.517           547\n",
      "24   8.50     4574      2619  0.551           460\n",
      "25   9.00     3721      4746  0.544           566\n",
      "26   8.00     3448      5399  0.548           577\n",
      "27   7.50     3846      9061  0.579           631\n",
      "28   8.00     4188      5975  0.563           574\n",
      "29   9.00     3601      4650  0.493           534\n",
      "30   7.00     3640      6905  0.518           571\n",
      "31   7.00     3333      6594  0.513           554\n",
      "32   8.00     3063      6524  0.578           577\n",
      "33   7.50     3357      4121  0.547           628\n",
      "34   8.00     3528      3495  0.487           487\n",
      "35   6.58     3802      7834  0.629           644\n",
      "36   5.00     4045     17782  0.566           640\n",
      "37   7.00     3897      6385  0.586           704\n",
      "38   8.50     3635      3274  0.663           648\n",
      "39   7.00     4345      3905  0.672           968\n",
      "40   7.00     4449      4639  0.626           587\n",
      "41   7.00     3656      3985  0.563           699\n",
      "42   7.00     4300      3635  0.603           632\n",
      "43   7.00     3745      2611  0.508           591\n",
      "44   6.00     5215      2302  0.672           782\n",
      "45   9.00     4476      3942  0.571           510\n",
      "46   7.00     4296      4083  0.623           610\n",
      "47   7.00     5002      9794  0.593           524\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"petrol.csv\")\n",
    "#checking head, tail and shape of data that is loaded\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "print(df.shape)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tax</th>\n",
       "      <th>income</th>\n",
       "      <th>highway</th>\n",
       "      <th>dl</th>\n",
       "      <th>consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.668333</td>\n",
       "      <td>4241.833333</td>\n",
       "      <td>5565.416667</td>\n",
       "      <td>0.570333</td>\n",
       "      <td>576.770833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.950770</td>\n",
       "      <td>573.623768</td>\n",
       "      <td>3491.507166</td>\n",
       "      <td>0.055470</td>\n",
       "      <td>111.885816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>3063.000000</td>\n",
       "      <td>431.000000</td>\n",
       "      <td>0.451000</td>\n",
       "      <td>344.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>3739.000000</td>\n",
       "      <td>3110.250000</td>\n",
       "      <td>0.529750</td>\n",
       "      <td>509.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.500000</td>\n",
       "      <td>4298.000000</td>\n",
       "      <td>4735.500000</td>\n",
       "      <td>0.564500</td>\n",
       "      <td>568.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.125000</td>\n",
       "      <td>4578.750000</td>\n",
       "      <td>7156.000000</td>\n",
       "      <td>0.595250</td>\n",
       "      <td>632.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>5342.000000</td>\n",
       "      <td>17782.000000</td>\n",
       "      <td>0.724000</td>\n",
       "      <td>968.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tax       income       highway         dl   consumption\n",
       "count  48.000000    48.000000     48.000000  48.000000     48.000000\n",
       "mean    7.668333  4241.833333   5565.416667   0.570333    576.770833\n",
       "std     0.950770   573.623768   3491.507166   0.055470    111.885816\n",
       "min     5.000000  3063.000000    431.000000   0.451000    344.000000\n",
       "25%     7.000000  3739.000000   3110.250000   0.529750    509.500000\n",
       "50%     7.500000  4298.000000   4735.500000   0.564500    568.500000\n",
       "75%     8.125000  4578.750000   7156.000000   0.595250    632.750000\n",
       "max    10.000000  5342.000000  17782.000000   0.724000    968.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n",
    "#new_data = pd.series(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - Cap outliers \n",
    "\n",
    "Find the outliers and cap them. (Use (Q1 - 1.5 * IQR) as the minimum cap and (Q3 + 1.5 * IQR) as the max cap. The decision criteria is you should consider the datapoints which only falls within this range. The data points which fall outside this range are outliers and the entire row needs to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tax</th>\n",
       "      <th>income</th>\n",
       "      <th>highway</th>\n",
       "      <th>dl</th>\n",
       "      <th>consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.00</td>\n",
       "      <td>3571</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>0.525</td>\n",
       "      <td>541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.00</td>\n",
       "      <td>4092</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.572</td>\n",
       "      <td>524.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.00</td>\n",
       "      <td>3865</td>\n",
       "      <td>1586.0</td>\n",
       "      <td>0.580</td>\n",
       "      <td>561.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.50</td>\n",
       "      <td>4870</td>\n",
       "      <td>2351.0</td>\n",
       "      <td>0.529</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.00</td>\n",
       "      <td>4399</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>410.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.00</td>\n",
       "      <td>5319</td>\n",
       "      <td>11868.0</td>\n",
       "      <td>0.451</td>\n",
       "      <td>344.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.00</td>\n",
       "      <td>5126</td>\n",
       "      <td>2138.0</td>\n",
       "      <td>0.553</td>\n",
       "      <td>467.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.00</td>\n",
       "      <td>4447</td>\n",
       "      <td>8577.0</td>\n",
       "      <td>0.529</td>\n",
       "      <td>464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4512</td>\n",
       "      <td>8507.0</td>\n",
       "      <td>0.552</td>\n",
       "      <td>498.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.00</td>\n",
       "      <td>4391</td>\n",
       "      <td>5939.0</td>\n",
       "      <td>0.530</td>\n",
       "      <td>580.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4817</td>\n",
       "      <td>6930.0</td>\n",
       "      <td>0.574</td>\n",
       "      <td>525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4207</td>\n",
       "      <td>6580.0</td>\n",
       "      <td>0.545</td>\n",
       "      <td>508.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4332</td>\n",
       "      <td>8159.0</td>\n",
       "      <td>0.608</td>\n",
       "      <td>566.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4318</td>\n",
       "      <td>10340.0</td>\n",
       "      <td>0.586</td>\n",
       "      <td>635.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4206</td>\n",
       "      <td>8508.0</td>\n",
       "      <td>0.572</td>\n",
       "      <td>603.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3718</td>\n",
       "      <td>4725.0</td>\n",
       "      <td>0.540</td>\n",
       "      <td>714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8.50</td>\n",
       "      <td>4341</td>\n",
       "      <td>6010.0</td>\n",
       "      <td>0.677</td>\n",
       "      <td>640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4593</td>\n",
       "      <td>7834.0</td>\n",
       "      <td>0.663</td>\n",
       "      <td>649.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8.00</td>\n",
       "      <td>4983</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.602</td>\n",
       "      <td>540.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9.00</td>\n",
       "      <td>4897</td>\n",
       "      <td>2449.0</td>\n",
       "      <td>0.511</td>\n",
       "      <td>464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9.00</td>\n",
       "      <td>4258</td>\n",
       "      <td>4686.0</td>\n",
       "      <td>0.517</td>\n",
       "      <td>547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8.50</td>\n",
       "      <td>4574</td>\n",
       "      <td>2619.0</td>\n",
       "      <td>0.551</td>\n",
       "      <td>460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9.00</td>\n",
       "      <td>3721</td>\n",
       "      <td>4746.0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>566.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8.00</td>\n",
       "      <td>3448</td>\n",
       "      <td>5399.0</td>\n",
       "      <td>0.548</td>\n",
       "      <td>577.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7.50</td>\n",
       "      <td>3846</td>\n",
       "      <td>9061.0</td>\n",
       "      <td>0.579</td>\n",
       "      <td>631.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8.00</td>\n",
       "      <td>4188</td>\n",
       "      <td>5975.0</td>\n",
       "      <td>0.563</td>\n",
       "      <td>574.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9.00</td>\n",
       "      <td>3601</td>\n",
       "      <td>4650.0</td>\n",
       "      <td>0.493</td>\n",
       "      <td>534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3640</td>\n",
       "      <td>6905.0</td>\n",
       "      <td>0.518</td>\n",
       "      <td>571.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3333</td>\n",
       "      <td>6594.0</td>\n",
       "      <td>0.513</td>\n",
       "      <td>554.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8.00</td>\n",
       "      <td>3063</td>\n",
       "      <td>6524.0</td>\n",
       "      <td>0.578</td>\n",
       "      <td>577.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7.50</td>\n",
       "      <td>3357</td>\n",
       "      <td>4121.0</td>\n",
       "      <td>0.547</td>\n",
       "      <td>628.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>8.00</td>\n",
       "      <td>3528</td>\n",
       "      <td>3495.0</td>\n",
       "      <td>0.487</td>\n",
       "      <td>487.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>6.58</td>\n",
       "      <td>3802</td>\n",
       "      <td>7834.0</td>\n",
       "      <td>0.629</td>\n",
       "      <td>644.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3897</td>\n",
       "      <td>6385.0</td>\n",
       "      <td>0.586</td>\n",
       "      <td>704.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>8.50</td>\n",
       "      <td>3635</td>\n",
       "      <td>3274.0</td>\n",
       "      <td>0.663</td>\n",
       "      <td>648.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4449</td>\n",
       "      <td>4639.0</td>\n",
       "      <td>0.626</td>\n",
       "      <td>587.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3656</td>\n",
       "      <td>3985.0</td>\n",
       "      <td>0.563</td>\n",
       "      <td>699.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4300</td>\n",
       "      <td>3635.0</td>\n",
       "      <td>0.603</td>\n",
       "      <td>632.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>7.00</td>\n",
       "      <td>3745</td>\n",
       "      <td>2611.0</td>\n",
       "      <td>0.508</td>\n",
       "      <td>591.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>6.00</td>\n",
       "      <td>5215</td>\n",
       "      <td>2302.0</td>\n",
       "      <td>0.672</td>\n",
       "      <td>782.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>9.00</td>\n",
       "      <td>4476</td>\n",
       "      <td>3942.0</td>\n",
       "      <td>0.571</td>\n",
       "      <td>510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>7.00</td>\n",
       "      <td>4296</td>\n",
       "      <td>4083.0</td>\n",
       "      <td>0.623</td>\n",
       "      <td>610.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>7.00</td>\n",
       "      <td>5002</td>\n",
       "      <td>9794.0</td>\n",
       "      <td>0.593</td>\n",
       "      <td>524.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tax   income   highway     dl   consumption\n",
       "0   9.00     3571    1976.0  0.525         541.0\n",
       "1   9.00     4092    1250.0  0.572         524.0\n",
       "2   9.00     3865    1586.0  0.580         561.0\n",
       "3   7.50     4870    2351.0  0.529         414.0\n",
       "4   8.00     4399     431.0  0.544         410.0\n",
       "6   8.00     5319   11868.0  0.451         344.0\n",
       "7   8.00     5126    2138.0  0.553         467.0\n",
       "8   8.00     4447    8577.0  0.529         464.0\n",
       "9   7.00     4512    8507.0  0.552         498.0\n",
       "10  8.00     4391    5939.0  0.530         580.0\n",
       "12  7.00     4817    6930.0  0.574         525.0\n",
       "13  7.00     4207    6580.0  0.545         508.0\n",
       "14  7.00     4332    8159.0  0.608         566.0\n",
       "15  7.00     4318   10340.0  0.586         635.0\n",
       "16  7.00     4206    8508.0  0.572         603.0\n",
       "17  7.00     3718    4725.0  0.540         714.0\n",
       "19  8.50     4341    6010.0  0.677         640.0\n",
       "20  7.00     4593    7834.0  0.663         649.0\n",
       "21  8.00     4983     602.0  0.602         540.0\n",
       "22  9.00     4897    2449.0  0.511         464.0\n",
       "23  9.00     4258    4686.0  0.517         547.0\n",
       "24  8.50     4574    2619.0  0.551         460.0\n",
       "25  9.00     3721    4746.0  0.544         566.0\n",
       "26  8.00     3448    5399.0  0.548         577.0\n",
       "27  7.50     3846    9061.0  0.579         631.0\n",
       "28  8.00     4188    5975.0  0.563         574.0\n",
       "29  9.00     3601    4650.0  0.493         534.0\n",
       "30  7.00     3640    6905.0  0.518         571.0\n",
       "31  7.00     3333    6594.0  0.513         554.0\n",
       "32  8.00     3063    6524.0  0.578         577.0\n",
       "33  7.50     3357    4121.0  0.547         628.0\n",
       "34  8.00     3528    3495.0  0.487         487.0\n",
       "35  6.58     3802    7834.0  0.629         644.0\n",
       "37  7.00     3897    6385.0  0.586         704.0\n",
       "38  8.50     3635    3274.0  0.663         648.0\n",
       "40  7.00     4449    4639.0  0.626         587.0\n",
       "41  7.00     3656    3985.0  0.563         699.0\n",
       "42  7.00     4300    3635.0  0.603         632.0\n",
       "43  7.00     3745    2611.0  0.508         591.0\n",
       "44  6.00     5215    2302.0  0.672         782.0\n",
       "45  9.00     4476    3942.0  0.571         510.0\n",
       "46  7.00     4296    4083.0  0.623         610.0\n",
       "47  7.00     5002    9794.0  0.593         524.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1 = df.quantile(0.25)\n",
    "q3 = df.quantile(0.75)\n",
    "IQR = q3 - q1\n",
    "minCap = q1 - (1.5 * IQR)\n",
    "maxCap = q3 + (1.5 * IQR)\n",
    "petrol_df = df.where((df>= minCap)&(df<=maxCap))\n",
    "#drop NaN rows\n",
    "petrol_df.dropna(axis = 0, how = 'any',inplace = True)\n",
    "petrol_df.shape\n",
    "petrol_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14e3c62ea58>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(petrol_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 - Independent variables and collinearity \n",
    "Which attributes seems to have stronger association with the dependent variable consumption?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the correlation matrix is \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tax</th>\n",
       "      <th>income</th>\n",
       "      <th>highway</th>\n",
       "      <th>dl</th>\n",
       "      <th>consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tax</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.109537</td>\n",
       "      <td>-0.390602</td>\n",
       "      <td>-0.314702</td>\n",
       "      <td>-0.446116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>-0.109537</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051169</td>\n",
       "      <td>0.150689</td>\n",
       "      <td>-0.347326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>highway</th>\n",
       "      <td>-0.390602</td>\n",
       "      <td>0.051169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.016193</td>\n",
       "      <td>0.034309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dl</th>\n",
       "      <td>-0.314702</td>\n",
       "      <td>0.150689</td>\n",
       "      <td>-0.016193</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.611788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>consumption</th>\n",
       "      <td>-0.446116</td>\n",
       "      <td>-0.347326</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.611788</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tax    income   highway        dl   consumption\n",
       "tax           1.000000 -0.109537 -0.390602 -0.314702     -0.446116\n",
       " income      -0.109537  1.000000  0.051169  0.150689     -0.347326\n",
       " highway     -0.390602  0.051169  1.000000 -0.016193      0.034309\n",
       " dl          -0.314702  0.150689 -0.016193  1.000000      0.611788\n",
       " consumption -0.446116 -0.347326  0.034309  0.611788      1.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = petrol_df.corr()\n",
    "print(\"the correlation matrix is \")\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the above correlation matrix it is clear that DL has highest correlation with consumption then comes highway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observing the above correlation values between all the variables, we can see that there is stronger association between the number of drivers and consumption. And comparatively tax has an association in a negative way. \n",
    "Insights :\n",
    "As tax increases the consumption decreases.\n",
    "As number of drivers is more consumption is more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4 - Transform the dataset \n",
    "Divide the data into feature(X) and target(Y) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = petrol_df[[' dl']]\n",
    "Y = petrol_df[[' consumption']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 - Split data into train, test sets \n",
    "Divide the data into training and test sets with 80-20 split using scikit-learn. Print the shapes of training and test feature sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1)\n",
      "(11, 1)\n",
      "(32, 1)\n",
      "(11, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, x_test, Y_train, y_test = train_test_split(X,Y,  random_state = 100)\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Create linear regression object\n",
    "regressor = linear_model.LinearRegression()\n",
    "print(X_train.shape)\n",
    "print(x_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(x_test.shape)\n",
    "# Train the model using the training sets\n",
    "regressor.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6 - Build Model \n",
    "Estimate the coefficients for each input feature. Construct and display a dataframe with coefficients and X.columns as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1080.33565344]] [-42.78206719]\n",
      "  Coeffecients               Columns\n",
      "0           dl  [1080.3356534446038]\n"
     ]
    }
   ],
   "source": [
    "coeff = regressor.coef_\n",
    "intercept = regressor.intercept_\n",
    "print(coeff,intercept)\n",
    "#X.columns\n",
    "#one_varibale_data = {coeff,}\n",
    "column_values = X.columns\n",
    "df_one_variable = pd.DataFrame([column_values, coeff],index = {\"Columns\", \"Coeffecients\"}).T\n",
    "print(df_one_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R-Square "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7 - Evaluate the model \n",
    "Calculate the accuracy score for the above model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16427399177648572\n",
      "6159.31449426033\n",
      "78.4813002839551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16427399177648572"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y = coeff * X_train + intercept\n",
    "y_pred = regressor.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "plt.scatter(x_test, y_test,  color='black')\n",
    "plt.plot(x_test, y_pred, color='blue', linewidth=3)\n",
    "print(r2_score(y_test,y_pred))\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)\n",
    "rmse = sqrt(mse)\n",
    "print(rmse)\n",
    "regressor.score(X_train,Y_train) #checking score for training data\n",
    "regressor.score(x_test,y_test) # checking score for test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 8: Repeat the same Multi linear regression modelling by adding both Income and Highway features\n",
    "Find R2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking new vairables for mmulti linear regression\n",
    "new_X = petrol_df[[' income',' highway',' dl']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_Y = petrol_df[[' consumption']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 9: Print the coefficients of the multilinear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X_train, new_x_test, new_Y_train, new_y_test = train_test_split(new_X,New_Y,  random_state = 100)\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Create linear regression object\n",
    "new_regressor = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "new_regressor.fit(new_X_train, new_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.03547648e-02  4.02718505e-03  1.18915255e+03]] [80.53871683]\n"
     ]
    }
   ],
   "source": [
    "new_coeff = new_regressor.coef_\n",
    "new_intercept = new_regressor.intercept_\n",
    "print(new_coeff,new_intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5811382874762809"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_regressor.score(new_X_train,new_Y_train) #checking score for training data\n",
    "new_regressor.score(new_x_test,new_y_test) # checking score for test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 10 \n",
    "In one or two sentences give reasoning on R-Square on the basis of above findings\n",
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *R squared value increase if we increase the number of independent variables to our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            consumption   R-squared:                       0.992\n",
      "Model:                            OLS   Adj. R-squared:                  0.989\n",
      "Method:                 Least Squares   F-statistic:                     331.3\n",
      "Date:                Sun, 02 Jun 2019   Prob (F-statistic):           9.97e-09\n",
      "Time:                        22:39:29   Log-Likelihood:                -58.262\n",
      "No. Observations:                  11   AIC:                             122.5\n",
      "Df Residuals:                       8   BIC:                             123.7\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      " income       -0.0964      0.029     -3.354      0.010      -0.163      -0.030\n",
      " highway       0.0053      0.006      0.933      0.378      -0.008       0.019\n",
      " dl         1702.6490    211.191      8.062      0.000    1215.643    2189.655\n",
      "==============================================================================\n",
      "Omnibus:                        0.877   Durbin-Watson:                   2.583\n",
      "Prob(Omnibus):                  0.645   Jarque-Bera (JB):                0.618\n",
      "Skew:                           0.008   Prob(JB):                        0.734\n",
      "Kurtosis:                       1.839   Cond. No.                     8.65e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 8.65e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "\n",
      "values for one variable results\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            consumption   R-squared:                       0.980\n",
      "Model:                            OLS   Adj. R-squared:                  0.978\n",
      "Method:                 Least Squares   F-statistic:                     486.6\n",
      "Date:                Sun, 02 Jun 2019   Prob (F-statistic):           8.22e-10\n",
      "Time:                        22:39:29   Log-Likelihood:                -63.349\n",
      "No. Observations:                  11   AIC:                             128.7\n",
      "Df Residuals:                      10   BIC:                             129.1\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      " dl          976.2436     44.258     22.058      0.000     877.631    1074.856\n",
      "==============================================================================\n",
      "Omnibus:                        1.155   Durbin-Watson:                   2.713\n",
      "Prob(Omnibus):                  0.561   Jarque-Bera (JB):                0.892\n",
      "Skew:                           0.485   Prob(JB):                        0.640\n",
      "Kurtosis:                       1.998   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1394: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=11\n",
      "  \"anyway, n=%i\" % int(n))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1394: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=11\n",
      "  \"anyway, n=%i\" % int(n))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (11,3) and (4,1) not aligned: 3 (dim 1) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-138eb8311d4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\\nvalues for one variable results\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_variable_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mnew_y_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_regressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_x_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew_y_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \"\"\"\n\u001b[1;32m--> 256\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[1;32m--> 241\u001b[1;33m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (11,3) and (4,1) not aligned: 3 (dim 1) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "#using ordinary least square method for finding R squared\n",
    "import statsmodels.api as sm\n",
    "\n",
    "results  = sm.OLS(endog = new_y_test, exog = new_x_test).fit()\n",
    "print(results.summary())\n",
    "one_variable_results  = sm.OLS(endog = y_test, exog = x_test).fit()\n",
    "print(\"\\n\\nvalues for one variable results\")\n",
    "print(one_variable_results.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_var_X = petrol_df[['tax',' income',' highway',' dl']]\n",
    "four_var_Y = petrol_df[[' consumption']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "four_var_X_train, four_var_x_test, four_var_Y_train, four_var_y_test = train_test_split(four_var_X,four_var_Y,  random_state = 100)\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Create linear regression object\n",
    "four_var_regressor = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "four_var_regressor.fit(four_var_X_train, four_var_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.03547648e-02  4.02718505e-03  1.18915255e+03]] [80.53871683]\n"
     ]
    }
   ],
   "source": [
    "four_var_coeff = new_regressor.coef_\n",
    "four_var_intercept = new_regressor.intercept_\n",
    "print(new_coeff,new_intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.601479996424205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7392922309610579"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(four_var_regressor.score(four_var_X_train,four_var_Y_train)) #checking score for training data\n",
    "four_var_regressor.score(four_var_x_test,four_var_y_test) # checking score for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2754.6414845993468 52.484678570029814\n"
     ]
    }
   ],
   "source": [
    "alpre=four_var_regressor.fit(four_var_X_train,four_var_Y_train)\n",
    "y_alpredict=alpre.predict(four_var_X_train)\n",
    "y_pred = four_var_regressor.predict(four_var_X_train)\n",
    "mse = mean_squared_error(four_var_Y_train, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "print(mse,rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
